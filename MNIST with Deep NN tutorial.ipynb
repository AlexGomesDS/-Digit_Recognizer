{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "73f2e49e-67b8-41e5-880f-a6800c398187",
    "_uuid": "373f1724c8fb586c0a35ce2569373b1e2779c2f9"
   },
   "source": [
    "# Tensorflow tutorial on MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "fae555b5-3fa8-4b4a-bb49-4c1ddd35ffe0",
    "_uuid": "faab87250004262b73dcb1e5a1e623ecc892654b",
    "colab_type": "text",
    "id": "W_Hghyj7h2Zz"
   },
   "source": [
    "### Resources\n",
    "\n",
    "\n",
    "\n",
    "*   Tutorial: https://www.tensorflow.org/versions/r1.1/get_started/mnist/beginners\n",
    "*   Code: https://github.com/tensorflow/tensorflow/blob/r1.1/tensorflow/examples/tutorials/mnist/mnist_softmax.py\n",
    "\n",
    "Posts to check later:\n",
    "*   Really cool post about **dim reduction**: http://colah.github.io/posts/2014-10-Visualizing-MNIST/\n",
    "*   Visual interpretation of NN: [http://colah.github.io/posts/2014-03-NN-Manifolds-Topology/](http://colah.github.io/posts/2014-03-NN-Manifolds-Topology/)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "0bd40799-03d6-45a6-8210-2932e0be9774",
    "_uuid": "55a6e69cda8477895a83415664dadc1d364c737c",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 122,
     "output_extras": [
      {
       "item_id": 2
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 966,
     "status": "ok",
     "timestamp": 1520188759988,
     "user": {
      "displayName": "Alexandre Gomes",
      "photoUrl": "//lh4.googleusercontent.com/-0SJODzHVIXQ/AAAAAAAAAAI/AAAAAAAAUeU/Cs1pVksWH3I/s50-c-k-no/photo.jpg",
      "userId": "108678232453929155174"
     },
     "user_tz": 0
    },
    "id": "9X2lJKJhSchd",
    "outputId": "b64849a8-05dc-4b95-f4d9-1729c25ba8b7"
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named tensorflow",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-a34d6351d2fd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mu'matplotlib notebook'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: No module named tensorflow"
     ]
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt \n",
    "%matplotlib notebook\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from time import sleep as pause"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "bff69ef5-56ff-4dc5-9834-63e5db1225fc",
    "_uuid": "29c8f11c41af66a805dd3c4b54e5e8db1a227667"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-531d82a8f667>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m#build a csv line parser (https://www.tensorflow.org/get_started/datasets_quickstart)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mCOLUMNS\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_path\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mFIELD_DEFAULTS\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0.0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mCOLUMNS\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_parse_line\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "train_path = '../input/train.csv'\n",
    "test_path = '../input/train.csv'\n",
    "#build a csv line parser (https://www.tensorflow.org/get_started/datasets_quickstart)\n",
    "batch_size = 100\n",
    "COLUMNS = pd.read_csv(train_path,nrows=1).columns\n",
    "FIELD_DEFAULTS = [[0.0]]*COLUMNS.size\n",
    "def _parse_line(line):\n",
    "    fields = tf.decode_csv(line, FIELD_DEFAULTS)\n",
    "    features = dict(zip(COLUMNS, fields))\n",
    "    label = features.pop('label')\n",
    "    return features#, label\n",
    "\n",
    "train_dataset = tf.data.TextLineDataset(train_path).skip(1)\n",
    "train_dataset = train_dataset.map(_parse_line)#.shuffle(1000000).repeat().batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "03d0100c-5e2b-4db1-a396-44edecb20696",
    "_uuid": "d4c593042c877a2706af3b7ba86e867bbbe894c9",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_input_fn(features):\n",
    "    #dataset = tf.data.Dataset.from_tensor_slices((dict(features), labels))\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(dict(features))\n",
    "    dataset = dataset.shuffle(1000).repeat().batch(batch_size)\n",
    "    return dataset.make_one_shot_iterator().get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "ee622d6a-557a-4adc-8846-08f18e658b0b",
    "_uuid": "955b280a98dd782eaf49af3254c4680dfab0114f",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.run(train_input_fn(train_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "17e4c88b-0dab-466f-8c23-84609b7f3b6a",
    "_uuid": "d912192a0d4bdd95746eabc1ce5d7d22943aef2e"
   },
   "source": [
    "#### Build dataset structures as in the tutorial from the CSVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "f2aa74e8-f55b-45ce-9ea4-1e962adbd312",
    "_uuid": "83f5ec46931fd569347ba7befad186252ec5e444",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_raw_data = pd.read_csv('../input/train.csv').sample(100)\n",
    "test_raw_data = pd.read_csv('../input/train.csv').sample(100)\n",
    "\n",
    "# create tensors\n",
    "train_labels, train_images = train_raw_data.pop(\"label\").values, train_raw_data.values\n",
    "test_labels, test_images = test_raw_data.pop(\"label\").values, test_raw_data.values\n",
    "\n",
    "# apply one hot encoding to the labels\n",
    "OHEnconder = OneHotEncoder()\n",
    "train_labels = OHEnconder.fit_transform(train_labels.reshape(-1,1)).toarray()\n",
    "test_labels = OHEnconder.fit_transform(test_labels.reshape(-1,1)).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "c266cb50-64f6-4734-99f4-52fa2ad921b8",
    "_uuid": "9a55921d3c6869e23439b9fcf9781cc14c7ad09f"
   },
   "source": [
    "### Build and run Tensorflow session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "bd05e695-a77e-44ee-82c9-c0267c96c432",
    "_uuid": "74d51be704d3fac1843e10dd2cf5efd8f49d3599",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "R02E6_CzufVH"
   },
   "outputs": [],
   "source": [
    "def normalize(X):#linear rescaling to the range [-1,1]\n",
    "    rg = (X.max()-X.min())\n",
    "    return np.zeros(X.shape) if rg==0 else (X-X.min())/rg\n",
    "\n",
    "\n",
    "# initialize input placeholders and model variables\n",
    "x = tf.placeholder(tf.float32, [None,784])\n",
    "y_ = tf.placeholder(tf.float32, [None,10])\n",
    "\n",
    "W = tf.Variable(tf.zeros([784, 10])) # no hidden layers: input layer fully connected to the output layer\n",
    "b = tf.Variable(tf.zeros([10]))    \n",
    "\n",
    "# specify model output\n",
    "y = tf.matmul(x, W) + b\n",
    "\n",
    "# define loss function. Calculated from the cross entropy between the estimated output and the true label\n",
    "# loss_func = tf.reduce_mean( - tf.reduce_sum(y_ * tf.log(tf.softmax(y)),reduction_indices = [1]))# explicit implementation of cross entropy\n",
    "loss_func = tf.reduce_mean( tf.nn.softmax_cross_entropy_with_logits_v2(labels=y_,logits=y)) #nuerically stable implementation from tf\n",
    "loss=[]\n",
    "\n",
    "# define what to do in each training iteration\n",
    "train_step = tf.train.GradientDescentOptimizer(0.5).minimize(loss_func)\n",
    "\n",
    "#Start a tensorflow session and initialize variables\n",
    "sess = tf.InteractiveSession()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "\n",
    "# Define accuracy\n",
    "calc_accuracy = tf.reduce_mean(tf.cast(tf.equal(tf.argmax(y,1), tf.argmax(y_,1)),tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "51f5a8d4-4dc8-499c-9f24-30084ac35dba",
    "_uuid": "104655c82d963d2048faeecc0e4b8418275c0b62",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 51,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "collapsed": true,
    "executionInfo": {
     "elapsed": 512,
     "status": "ok",
     "timestamp": 1520192904983,
     "user": {
      "displayName": "Alexandre Gomes",
      "photoUrl": "//lh4.googleusercontent.com/-0SJODzHVIXQ/AAAAAAAAAAI/AAAAAAAAUeU/Cs1pVksWH3I/s50-c-k-no/photo.jpg",
      "userId": "108678232453929155174"
     },
     "user_tz": 0
    },
    "id": "nPNU-LDlgAt7",
    "outputId": "1b210c70-5063-4e91-f7a2-eb02808d067d"
   },
   "outputs": [],
   "source": [
    "# evaluate model accuracy before training. All weights and biases set to 0 so it should classify everythin as a 0\n",
    "print(\"Percentage of 0's in the test set: {:.3f}\".format(test_labels.sum(axis=0)[0]/test_labels.sum()))\n",
    "\n",
    "acc =  sess.run(calc_accuracy, feed_dict={x: test_images,y_: test_labels})\n",
    "print(\"Model accuracy: {:.3f}\".format(acc))\n",
    "\n",
    "plt.ion()\n",
    "fig = plt.figure(1,figsize=(10, 7))\n",
    "plots = []\n",
    "for i in range(3):\n",
    "    for j in range(1,4):\n",
    "        ind = i*3+j\n",
    "        plt.subplot(3,3,ind)\n",
    "        plt.axis('off')\n",
    "        plt.tight_layout()\n",
    "        plots.append(plt.imshow(np.zeros([28,28]),cmap='plasma',clim=(-1, 1)))\n",
    "        plt.title(ind-1)\n",
    "\n",
    "def refresh_plots(list_of_plots, data):\n",
    "    for ind, plot in enumerate(plots):\n",
    "        plot.set_data(normalize(data[:,ind]).reshape(28,28))\n",
    "    fig.canvas.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "2baa785d-3d2c-4567-9e32-8cefed2cc9d0",
    "_uuid": "51a09eac71524b9c82f840a256f2e66a3f4910fa",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 1693,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "collapsed": true,
    "executionInfo": {
     "elapsed": 560,
     "status": "error",
     "timestamp": 1520193056340,
     "user": {
      "displayName": "Alexandre Gomes",
      "photoUrl": "//lh4.googleusercontent.com/-0SJODzHVIXQ/AAAAAAAAAAI/AAAAAAAAUeU/Cs1pVksWH3I/s50-c-k-no/photo.jpg",
      "userId": "108678232453929155174"
     },
     "user_tz": 0
    },
    "id": "GPjo9H-7fEZY",
    "outputId": "e862c660-82d5-4284-edfa-04c8508d41d9",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "N=1\n",
    "for i in range(10):\n",
    "    loss.append(sess.run(loss_func, feed_dict={x: test_images,y_: test_labels}))\n",
    "    sess.run(train_step, feed_dict={x: train_images, y_: train_labels})\n",
    "    if not i%N: #refresh weights plot every N steps\n",
    "        refresh_plots(plots, normalize(sess.run(W)))\n",
    "        pause(1)\n",
    "plt.figure(3)\n",
    "loss_function_plt = plt.plot(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "1b6d1871-0c25-4946-b778-ed879ecf9551",
    "_uuid": "907d7aa77ca33ab35f90591c7fdc10c607383ea7",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#W.initializer.run()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "default_view": {},
   "name": "MNIST with Deep NN tutorial.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
