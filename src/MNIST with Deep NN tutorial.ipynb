{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"MNIST with Deep NN tutorial.ipynb","version":"0.3.2","views":{},"default_view":{},"provenance":[]},"kernelspec":{"display_name":"Python 2","language":"python","name":"python2"}},"cells":[{"metadata":{"id":"q79mEHeIdDkz","colab_type":"text"},"cell_type":"markdown","source":["# Tensorflow tutorial on MNIST"]},{"metadata":{"id":"W_Hghyj7h2Zz","colab_type":"text"},"cell_type":"markdown","source":["### Resources\n","\n","\n","\n","*   Tutorial: https://www.tensorflow.org/versions/r1.1/get_started/mnist/beginners\n","*   Code: https://github.com/tensorflow/tensorflow/blob/r1.1/tensorflow/examples/tutorials/mnist/mnist_softmax.py\n","\n","Posts to check later:\n","*   Really cool post about **dim reduction**: http://colah.github.io/posts/2014-10-Visualizing-MNIST/\n","*   Visual interpretation of NN: [http://colah.github.io/posts/2014-03-NN-Manifolds-Topology/](http://colah.github.io/posts/2014-03-NN-Manifolds-Topology/)\n","\n"]},{"metadata":{"id":"9X2lJKJhSchd","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"output_extras":[{}],"base_uri":"https://localhost:8080/","height":122},"outputId":"b64849a8-05dc-4b95-f4d9-1729c25ba8b7","executionInfo":{"elapsed":966,"status":"ok","timestamp":1520188759988,"user":{"displayName":"Alexandre Gomes","photoUrl":"//lh4.googleusercontent.com/-0SJODzHVIXQ/AAAAAAAAAAI/AAAAAAAAUeU/Cs1pVksWH3I/s50-c-k-no/photo.jpg","userId":"108678232453929155174"},"user_tz":0}},"cell_type":"code","source":["from matplotlib import pyplot as plt \n","%matplotlib notebook\n","import tensorflow as tf\n","import pandas as pd\n","import numpy as np\n","from sklearn.preprocessing import OneHotEncoder\n","from time import sleep as pause"],"execution_count":0,"outputs":[{"output_type":"error","ename":"ImportError","evalue":"No module named tensorflow","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)","\u001b[1;32m<ipython-input-3-a34d6351d2fd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mu'matplotlib notebook'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;31mImportError\u001b[0m: No module named tensorflow"]}]},{"metadata":{"id":"kzaeDOlsdDlF","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"output_extras":[{}]},"outputId":"33bac6dc-c5fe-4de9-9c62-2eabf4cb6296"},"cell_type":"code","source":["train_path = '../input/train.csv'\n","test_path = '../input/train.csv'\n","#build a csv line parser (https://www.tensorflow.org/get_started/datasets_quickstart)\n","batch_size = 100\n","COLUMNS = pd.read_csv(train_path,nrows=1).columns\n","FIELD_DEFAULTS = [[0.0]]*COLUMNS.size\n","def _parse_line(line):\n","    fields = tf.decode_csv(line, FIELD_DEFAULTS)\n","    features = dict(zip(COLUMNS, fields))\n","    label = features.pop('label')\n","    return features#, label\n","\n","train_dataset = tf.data.TextLineDataset(train_path).skip(1)\n","train_dataset = train_dataset.map(_parse_line)#.shuffle(1000000).repeat().batch(batch_size)"],"execution_count":0,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'pd' is not defined","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[1;32m<ipython-input-2-531d82a8f667>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m#build a csv line parser (https://www.tensorflow.org/get_started/datasets_quickstart)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mCOLUMNS\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_path\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mFIELD_DEFAULTS\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0.0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mCOLUMNS\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_parse_line\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"]}]},{"metadata":{"id":"fySV1lpldDlP","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["def train_input_fn(features):\n","    #dataset = tf.data.Dataset.from_tensor_slices((dict(features), labels))\n","    dataset = tf.data.Dataset.from_tensor_slices(dict(features))\n","    dataset = dataset.shuffle(1000).repeat().batch(batch_size)\n","    return dataset.make_one_shot_iterator().get_next()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"1twTl5vsdDlV","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["sess.run(train_input_fn(train_dataset))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"77Cg6MnPdDla","colab_type":"text"},"cell_type":"markdown","source":["#### Build dataset structures as in the tutorial from the CSVs"]},{"metadata":{"id":"WBXqaOHIdDlb","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["train_raw_data = pd.read_csv('../input/train.csv').sample(100)\n","test_raw_data = pd.read_csv('../input/train.csv').sample(100)\n","\n","# create tensors\n","train_labels, train_images = train_raw_data.pop(\"label\").values, train_raw_data.values\n","test_labels, test_images = test_raw_data.pop(\"label\").values, test_raw_data.values\n","\n","# apply one hot encoding to the labels\n","OHEnconder = OneHotEncoder()\n","train_labels = OHEnconder.fit_transform(train_labels.reshape(-1,1)).toarray()\n","test_labels = OHEnconder.fit_transform(test_labels.reshape(-1,1)).toarray()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"UIV_h2zHdDlg","colab_type":"text"},"cell_type":"markdown","source":["### Build and run Tensorflow session"]},{"metadata":{"id":"R02E6_CzufVH","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["def normalize(X):#linear rescaling to the range [-1,1]\n","    rg = (X.max()-X.min())\n","    return np.zeros(X.shape) if rg==0 else (X-X.min())/rg\n","\n","\n","# initialize input placeholders and model variables\n","x = tf.placeholder(tf.float32, [None,784])\n","y_ = tf.placeholder(tf.float32, [None,10])\n","\n","W = tf.Variable(tf.zeros([784, 10])) # no hidden layers: input layer fully connected to the output layer\n","b = tf.Variable(tf.zeros([10]))    \n","\n","# specify model output\n","y = tf.matmul(x, W) + b\n","\n","# define loss function. Calculated from the cross entropy between the estimated output and the true label\n","# loss_func = tf.reduce_mean( - tf.reduce_sum(y_ * tf.log(tf.softmax(y)),reduction_indices = [1]))# explicit implementation of cross entropy\n","loss_func = tf.reduce_mean( tf.nn.softmax_cross_entropy_with_logits_v2(labels=y_,logits=y)) #nuerically stable implementation from tf\n","loss=[]\n","\n","# define what to do in each training iteration\n","train_step = tf.train.GradientDescentOptimizer(0.5).minimize(loss_func)\n","\n","#Start a tensorflow session and initialize variables\n","sess = tf.InteractiveSession()\n","init = tf.global_variables_initializer()\n","sess.run(init)\n","\n","# Define accuracy\n","calc_accuracy = tf.reduce_mean(tf.cast(tf.equal(tf.argmax(y,1), tf.argmax(y_,1)),tf.float32))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"nPNU-LDlgAt7","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# evaluate model accuracy before training. All weights and biases set to 0 so it should classify everythin as a 0\n","print(\"Percentage of 0's in the test set: {:.3f}\".format(test_labels.sum(axis=0)[0]/test_labels.sum()))\n","\n","acc =  sess.run(calc_accuracy, feed_dict={x: test_images,y_: test_labels})\n","print(\"Model accuracy: {:.3f}\".format(acc))\n","\n","plt.ion()\n","fig = plt.figure(1,figsize=(10, 7))\n","plots = []\n","for i in range(3):\n","    for j in range(1,4):\n","        ind = i*3+j\n","        plt.subplot(3,3,ind)\n","        plt.axis('off')\n","        plt.tight_layout()\n","        plots.append(plt.imshow(np.zeros([28,28]),cmap='plasma',clim=(-1, 1)))\n","        plt.title(ind-1)\n","\n","def refresh_plots(list_of_plots, data):\n","    for ind, plot in enumerate(plots):\n","        plot.set_data(normalize(data[:,ind]).reshape(28,28))\n","    fig.canvas.draw()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"GPjo9H-7fEZY","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["N=1\n","for i in range(10):\n","    loss.append(sess.run(loss_func, feed_dict={x: test_images,y_: test_labels}))\n","    sess.run(train_step, feed_dict={x: train_images, y_: train_labels})\n","    if not i%N: #refresh weights plot every N steps\n","        refresh_plots(plots, normalize(sess.run(W)))\n","        pause(1)\n","plt.figure(3)\n","loss_function_plt = plt.plot(loss)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"8zmT4i4BdDlx","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["#W.initializer.run()"],"execution_count":0,"outputs":[]}]}