{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "q79mEHeIdDkz"
   },
   "source": [
    "# Tensorflow tutorial on MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "W_Hghyj7h2Zz"
   },
   "source": [
    "### Resources\n",
    "\n",
    "\n",
    "\n",
    "*   Tutorial: https://www.tensorflow.org/versions/r1.1/get_started/mnist/beginners\n",
    "*   Code: https://github.com/tensorflow/tensorflow/blob/r1.1/tensorflow/examples/tutorials/mnist/mnist_softmax.py\n",
    "\n",
    "Posts to check later:\n",
    "*   Really cool post about **dim reduction**: http://colah.github.io/posts/2014-10-Visualizing-MNIST/\n",
    "*   Visual interpretation of NN: [http://colah.github.io/posts/2014-03-NN-Manifolds-Topology/](http://colah.github.io/posts/2014-03-NN-Manifolds-Topology/)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 122,
     "output_extras": [
      {}
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 966,
     "status": "ok",
     "timestamp": 1520188759988,
     "user": {
      "displayName": "Alexandre Gomes",
      "photoUrl": "//lh4.googleusercontent.com/-0SJODzHVIXQ/AAAAAAAAAAI/AAAAAAAAUeU/Cs1pVksWH3I/s50-c-k-no/photo.jpg",
      "userId": "108678232453929155174"
     },
     "user_tz": 0
    },
    "id": "9X2lJKJhSchd",
    "outputId": "b64849a8-05dc-4b95-f4d9-1729c25ba8b7"
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-029cf24be08b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'matplotlib'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'notebook'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt \n",
    "%matplotlib notebook\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from time import sleep as pause"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {}
     ]
    },
    "colab_type": "code",
    "id": "kzaeDOlsdDlF",
    "outputId": "33bac6dc-c5fe-4de9-9c62-2eabf4cb6296"
   },
   "outputs": [],
   "source": [
    "train_path = '../input/train.csv'\n",
    "test_path = '../input/train.csv'\n",
    "#build a csv line parser (https://www.tensorflow.org/get_started/datasets_quickstart)\n",
    "batch_size = 100\n",
    "COLUMNS = pd.read_csv(train_path,nrows=1).columns\n",
    "FIELD_DEFAULTS = [[0.0]]*COLUMNS.size\n",
    "def _parse_line(line):\n",
    "    fields = tf.decode_csv(line, FIELD_DEFAULTS)\n",
    "    features = dict(zip(COLUMNS, fields))\n",
    "    label = features.pop('label')\n",
    "    return features#, label\n",
    "\n",
    "train_dataset = tf.data.TextLineDataset(train_path).skip(1)\n",
    "train_dataset = train_dataset.map(_parse_line)#.shuffle(1000000).repeat().batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "fySV1lpldDlP"
   },
   "outputs": [],
   "source": [
    "def train_input_fn(features):\n",
    "    #dataset = tf.data.Dataset.from_tensor_slices((dict(features), labels))\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(dict(features))\n",
    "    dataset = dataset.shuffle(1000).repeat().batch(batch_size)\n",
    "    return dataset.make_one_shot_iterator().get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "1twTl5vsdDlV"
   },
   "outputs": [],
   "source": [
    "sess.run(train_input_fn(train_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "77Cg6MnPdDla"
   },
   "source": [
    "#### Build dataset structures as in the tutorial from the CSVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "WBXqaOHIdDlb"
   },
   "outputs": [],
   "source": [
    "train_raw_data = pd.read_csv('../input/train.csv').sample(100)\n",
    "test_raw_data = pd.read_csv('../input/train.csv').sample(100)\n",
    "\n",
    "# create tensors\n",
    "train_labels, train_images = train_raw_data.pop(\"label\").values, train_raw_data.values\n",
    "test_labels, test_images = test_raw_data.pop(\"label\").values, test_raw_data.values\n",
    "\n",
    "# apply one hot encoding to the labels\n",
    "OHEnconder = OneHotEncoder()\n",
    "train_labels = OHEnconder.fit_transform(train_labels.reshape(-1,1)).toarray()\n",
    "test_labels = OHEnconder.fit_transform(test_labels.reshape(-1,1)).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UIV_h2zHdDlg"
   },
   "source": [
    "### Build and run Tensorflow session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "R02E6_CzufVH"
   },
   "outputs": [],
   "source": [
    "def normalize(X):#linear rescaling to the range [-1,1]\n",
    "    rg = (X.max()-X.min())\n",
    "    return np.zeros(X.shape) if rg==0 else (X-X.min())/rg\n",
    "\n",
    "\n",
    "# initialize input placeholders and model variables\n",
    "x = tf.placeholder(tf.float32, [None,784])\n",
    "y_ = tf.placeholder(tf.float32, [None,10])\n",
    "\n",
    "W = tf.Variable(tf.zeros([784, 10])) # no hidden layers: input layer fully connected to the output layer\n",
    "b = tf.Variable(tf.zeros([10]))    \n",
    "\n",
    "# specify model output\n",
    "y = tf.matmul(x, W) + b\n",
    "\n",
    "# define loss function. Calculated from the cross entropy between the estimated output and the true label\n",
    "# loss_func = tf.reduce_mean( - tf.reduce_sum(y_ * tf.log(tf.softmax(y)),reduction_indices = [1]))# explicit implementation of cross entropy\n",
    "loss_func = tf.reduce_mean( tf.nn.softmax_cross_entropy_with_logits_v2(labels=y_,logits=y)) #nuerically stable implementation from tf\n",
    "loss=[]\n",
    "\n",
    "# define what to do in each training iteration\n",
    "train_step = tf.train.GradientDescentOptimizer(0.5).minimize(loss_func)\n",
    "\n",
    "#Start a tensorflow session and initialize variables\n",
    "sess = tf.InteractiveSession()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "\n",
    "# Define accuracy\n",
    "calc_accuracy = tf.reduce_mean(tf.cast(tf.equal(tf.argmax(y,1), tf.argmax(y_,1)),tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "nPNU-LDlgAt7"
   },
   "outputs": [],
   "source": [
    "# evaluate model accuracy before training. All weights and biases set to 0 so it should classify everythin as a 0\n",
    "print(\"Percentage of 0's in the test set: {:.3f}\".format(test_labels.sum(axis=0)[0]/test_labels.sum()))\n",
    "\n",
    "acc =  sess.run(calc_accuracy, feed_dict={x: test_images,y_: test_labels})\n",
    "print(\"Model accuracy: {:.3f}\".format(acc))\n",
    "\n",
    "plt.ion()\n",
    "fig = plt.figure(1,figsize=(10, 7))\n",
    "plots = []\n",
    "for i in range(3):\n",
    "    for j in range(1,4):\n",
    "        ind = i*3+j\n",
    "        plt.subplot(3,3,ind)\n",
    "        plt.axis('off')\n",
    "        plt.tight_layout()\n",
    "        plots.append(plt.imshow(np.zeros([28,28]),cmap='plasma',clim=(-1, 1)))\n",
    "        plt.title(ind-1)\n",
    "\n",
    "def refresh_plots(list_of_plots, data):\n",
    "    for ind, plot in enumerate(plots):\n",
    "        plot.set_data(normalize(data[:,ind]).reshape(28,28))\n",
    "    fig.canvas.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "GPjo9H-7fEZY"
   },
   "outputs": [],
   "source": [
    "N=1\n",
    "for i in range(10):\n",
    "    loss.append(sess.run(loss_func, feed_dict={x: test_images,y_: test_labels}))\n",
    "    sess.run(train_step, feed_dict={x: train_images, y_: train_labels})\n",
    "    if not i%N: #refresh weights plot every N steps\n",
    "        refresh_plots(plots, normalize(sess.run(W)))\n",
    "        pause(1)\n",
    "plt.figure(3)\n",
    "loss_function_plt = plt.plot(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "8zmT4i4BdDlx"
   },
   "outputs": [],
   "source": [
    "#W.initializer.run()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "default_view": {},
   "name": "MNIST with Deep NN tutorial.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "ldsa kernel",
   "language": "python",
   "name": "ldsa"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
